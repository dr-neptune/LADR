* Inner Product Spaces

In making the definition of a vector space, we generalized the linear structure (addition and scalar multiplication) of $R^2$ and $R^3$. We ignored other important features, such as the notions of length and angle. These ideas are embedded in the concept of inner products. 

** Learning Objectives for this Chapter 
*** Cauchy-Schwarz Inequality 
*** Gram-Schmidt Procedure 
*** Linear Functionals on Inner Product Spaces 
*** Calculating Minimum Distance to a Subspace 

** 6.A | Inner Products and Norms 

The length of the vector x is called the *norm* of x, and is denoted $\lVert x \rVert$. Thus for $x = (x_1, ..., x_n) \in R^n$, we have $\lVert x \rVert = \sqrt{x_1^2  + ... + x_n^2}$.

The norm is not linear on $R^n$ . To inject linearity into the discussion, we introduce the dot product. 

*** Definition | Dot Product 

For $x, y \in R^n$, the dot product of $x$ and $y$, denoted $x \cdot y$, is defined by $x \cdot y = x_1 y_1 + ... + x_n y_n$, where $x = (x_1, ..., x_n)$ and $y = (y_1, ..., y_n)$. 

The dot product on $R^n$ has the following properties: 

- $x \cdot x \geq 0$ for all $x \in R^n$
- $x \cdot x = 0$ iff $x = 0$
- for $y \in R^n$ fixed, the map from $R^n \to R$ that sends $x \in R^n$ to $x \cdot y$ is linear
- $x \cdot y = y \cdot x$ for all $x, y \in R^n$ 

*** Definition | Inner Product 

An inner product on $V$ is a function that takes each ordered pair $(u, v)$ of elements of $V$ to a number $\langle u, v \rangle \in F$ and has the following properties: 

- positivity : $\langle v, v \rangle \geq 0$ for all $v \in V$
- definiteness : $\langle v, v \rangle = 0$ iff $v = 0$
- additivity in first slot : $\langle u + v, w \rangle = \langle u, w \rangle + \langle v, w \rangle$ for all $u, v, w \in V$
- homogeneity in first slot : $\langle \lambda u, v \rangle = \lambda \langle u, v \rangle$ for all $\lambda \in F$ and all $u, v \in V$
- conjugate symmetry : $\langle u, v \rangle = \bar{\langle v, u \rangle}$ for all $u, v \in V$

*** Definition | Inner Product Space

An inner product space is a vector space $V$ along with an inner product on $V$. 

*** Theorem | Basic Properties of an Inner Product 

- For each fixed $u \in V$, the function that takes $v \to \langle v, u \rangle$ is a linear map from $V \to F$
- $\langle 0, u \rangle = 0$ for every $u \in V$ and vice versa
- $\langle u, v + w \rangle = \langle u, v \rangle + \langle u, w \rangle$ for all $u, v, w \in V$
- $\langle u, \lambda v \rangle = \bar{\lambda} \langle u, v \rangle$ for all $\lambda \in F$ and $u, v \in V$

*** Definition | norm, $\lVert v \rVert$

For $v \in V$, the norm of $v$, denoted $\lVert v \rVert$, is defined by $\lVert v \rVert = \sqrt{\langle v, v \rangle}$

*** Theorem | Basic Properties of the Norm 

Suppose $v \in V$

- $\lVert v \rVert = 0$ iff $v = 0$
- $\lVert \lambda v \rVert = \lvert \lambda \rvert \lVert v \rVert$ for all $\lambda \in F$

*** Definition | Orthogonal 

Two vectors $u, v \in V$ are called orthogonal if $\langle u, v \rangle = 0$ 

*** Theorem | Orthogonality and 0 

- 0 is orthogonal to every vector in $V$
- 0 is the only vector in $V$ that is orthogonal to itself 

*** Theorem | Pythagorean Theorem 

Suppose $u$ and $v$ are orthogonal vectors in $V$. Then $\lVert u + v \rVert^2 = \lVert u \rVert ^2 + \lVert v \rVert ^2$

*** Theorem | An Orthogonal Decomposition 

Suppose $u, v \in V$, with $v \neq 0$. Set $c = \frac{\langle u, v \rangle}{\lVert v \rVert^2}$ and $w = u - \frac{\langle u, v \rangle}{\lVert v \rVert^2} v$. Then $\langle w, v \rangle = 0$ and $u = cv + w$. 

*** Theorem | Cauchy-Schwarz Inequality 

Suppose $u, v \in V$. Then $\lvert \langle u, v \rangle \rvert \leq \lVert u \rVert \lVert v \rVert$. 

This inequality is an equality iff one of $u, v$ is a scalar multiple of each other.

*** Theorem | Triangle Inequality 

Suppose $u, v \in V$. Then $\lVert u + v \rVert \leq \lVert u \rVert + \lVert v \rVert$. 

This inequality is an equality iff one of $u, v$ is a non-negative multiple of the other.

*** Theorem | Parallelogram Equality 

Suppose $u, v \in V$. Then $\lVert u + v \rVert^2 + \lVert u - v \rVert^2 = 2 (\lVert u \rVert ^2 + \lVert v \rVert^2)$. 

** 6.B | Orthonormal Bases 

*** Definition | Orthonormal 

- A list of vectors is called orthonormal if each vector in the list has norm 1 and is orthogonal to all the other vectors in the list
- A list $e_1, ..., e_m$ of vectors in $V$ is orthonormal if $\langle e_j, e_k \rangle = 1$ if $j = k$, and 0 otherwise 

*** Theorem | The Norm of an Orthonormal Linear Combination 

If $e_1, ..., e_m$ is an orthonormal list of vectors in $V$, then $\lVert a_1 e_1 + ... + a_m e_m \rVert^2 = |a_1|^2 + ... + |a_m|^2$ for all $a_1, ..., a_m \in F$. 

*** Theorem | An Orthonormal List is Linearly Independent 

Every orthonormal list of vectors is linearly independent. 

*** Definition | Orthonormal Basis 

An orthonormal basis of $V$ is an orthnormal list of vectors in $V$ that is also a basis of $V$

*** Theorem | An Orthonormal List of the Right Length is an Orthonormal Basis 

Every orthonormal list of vectors in $V$ with length dim $V$ is an orthonormal basis of $V$

*** Theorem | Writing a Vector as a Linear Combination of Orthonormal Basis 

Suppose $e_1, ..., e_n$ is an orthonormal basis of $V$ and $v \in V$. Then $v = \langle v, e_1 \rangle e_1 + ... + \langle v, e_n \rangle e_n$ and $\lVert v \rVert^2 = |\langle v, e_1 \rangle |^2 + ... + |\langle v, e_n \rangle |^2$.

*** Theorem | Gram-Schmidt Procedure

This gives a method for turning a linearly independent list into an orthonormal list with the same span as the original list 

Suppose $v_1, ..., v_m$ is a linearly independent list of vectors in $V$. Let $e_1 = \frac{v_1}{\lVert v_1 \rVert}$. For $j = 2, ..., m$, define $e_j$ inductively by $e_j = \frac{v_j - \langle v_j, e_1 \rangle - ... - \langle v_j, e_{j - 1} \rangle e_{j - 1}}{\lVert v_j - \langle v_j, e_1 \rangle - ... - \langle v_j, e_{j - 1} \rangle e_{j - 1} \rVert}$. 

Then $e_1, ..., e_m$ is an orthonormal list of vectors in $V$ such that span$(v_1, ..., v_j)$ = span $(e_1, ..., e_j)$ for $j = 1, ..., m$

*** Theorem | Existence of Orthonormal Basis 

Every finite-dimensional inner product space has an orthonormal basis 

*** Theorem | Orthonormal List Extends to Orthonormal Basis 

Suppose $V$ is finite-dimensional. Then every orthonormal list of vectors in $V$ can be extended to an orthonormal basis of $V$. 

*** Theorem | Upper-Triangular Matrix with respect to Orthonormal Basis 

Suppose $T \in \mathcal{L}(V)$. If $T$ has an upper-triangular matrix with respect to some basis of $V$, then $T$ has an upper triangular matrix with respect to some orthonormal basis of $V$. 

*** Theorem | Schur's Theorem 

Suppose $V$ is a finite-dimensional complex vector space and $T \in \mathcal{L}(V)$. Then $T$ has an upper triangular matrix with respect to some orthonormal basis of $V$.

*** Definition | Linear Functional

A linear functional on $V$ is a linear map from $V$ to $F$. In other words, a linear function is an element of $\mathcal{L}(V, F)$. 

*** Theorem | Riesz Representation Theorem 


Suppose $V$ is finite-dimensional and $\gamma$ is a linear functional on $V$. Then there is a unique vector $u \in V$ such that $\gamma(v) = \langle v, u \rangle$ for every $v \in V$. 

** 6.C | Orthogonal Complements and Minimization Problems 

*** Definition | Orthogonal Complement $U^{\perp}$ 

If $U$ is a subset of $V$, then the orthogonal complement of $U$, denoted $U^{\perp}$, is the set of all vectors in $V$ that are orthogonal to every vector in $U$: $U^{\perp} = \{v \in V : \langle v, u \rangle = 0$ for all $u \in U\}$

*** Theorem | Basic Properties of Orthogonal Complement 

+ If $U$ is a subset of $V$, then $U^{\perp}$ is a subspace of $V$
+ $\{0\}^{\perp} = V$
+ $V^{\perp} = \{0\}$
+ If $U$ is a subset of $V$, then $U \cap U^{\perp} \subset \{0\}$
+ If $U$ and $W$ are subsets of $V$ and $U \subset W$, then $W^{\perp} \subset U^{\perp}$
